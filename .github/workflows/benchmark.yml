name: Service Mesh Benchmarks

"on":
  workflow_dispatch:
    inputs:
      mesh_type:
        description: Service mesh type to benchmark
        required: true
        default: baseline
        type: choice
        options:
          - baseline
          - istio
          - cilium
          - linkerd
      test_duration:
        description: Test duration in seconds
        required: false
        default: "60"
        type: string
      concurrent_connections:
        description: Number of concurrent connections
        required: false
        default: "100"
        type: string
  schedule:
    - cron: "0 2 * * 0"

jobs:
  benchmark:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install pydantic ruff black mypy

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~1.9"

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Configure cloud credentials
        run: |
          echo "Configuring Oracle Cloud Infrastructure credentials..."
          echo "⚠️  Cloud credentials not yet configured - skipping actual deployment"

      - name: Validate configuration
        run: |
          cd terraform/oracle-cloud
          terraform init -upgrade
          terraform validate

      - name: Run benchmark suite
        run: |
          cd tests
          python run_tests.py \
            --phase=all \
            --mesh-type=${{ github.event.inputs.mesh_type || 'baseline' }} \
            --test-duration=${{ github.event.inputs.test_duration || '60' }} \
            --concurrent-connections=${{ github.event.inputs.concurrent_connections || '100' }}
        env:
          MESH_TYPE: ${{ github.event.inputs.mesh_type || 'baseline' }}

      - name: Generate benchmark report
        if: always()
        run: |
          python generate-report.py \
            --results-dir=benchmarks/results \
            --output=benchmarks/results/report_${{ github.event.inputs.mesh_type || 'baseline' }}.html \
            --format=html

      - name: Generate JSON report
        if: always()
        run: |
          python generate-report.py \
            --results-dir=benchmarks/results \
            --output=benchmarks/results/report_${{ github.event.inputs.mesh_type || 'baseline' }}.json \
            --format=json

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.event.inputs.mesh_type || 'baseline' }}
          path: |
            benchmarks/results/*.html
            benchmarks/results/*.json
            benchmarks/results/*.csv
          retention-days: 90

      - name: Upload benchmark data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-raw-data-${{ github.event.inputs.mesh_type || 'baseline' }}
          path: benchmarks/results/
          retention-days: 90

  compare:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    strategy:
      matrix:
        mesh_type: [baseline, istio, cilium, linkerd]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install pydantic ruff black mypy

      - name: Run benchmark for ${{ matrix.mesh_type }}
        run: |
          cd tests
          python run_tests.py \
            --phase=all \
            --mesh-type=${{ matrix.mesh_type }} \
            --test-duration=300 \
            --concurrent-connections=200

      - name: Upload results for ${{ matrix.mesh_type }}
        uses: actions/upload-artifact@v4
        with:
          name: weekly-benchmark-${{ matrix.mesh_type }}
          path: benchmarks/results/
          retention-days: 90

  report:
    runs-on: ubuntu-latest
    needs: compare
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download all benchmark results
        uses: actions/download-artifact@v4
        with:
          path: benchmarks/results/

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pydantic

      - name: Generate comparison report
        run: |
          python generate-report.py \
            --results-dir=benchmarks/results \
            --output=benchmarks/results/weekly_comparison.html \
            --format=html

      - name: Upload comparison report
        uses: actions/upload-artifact@v4
        with:
          name: weekly-comparison-report
          path: benchmarks/results/weekly_comparison.html
          retention-days: 365
